# Implementation of a Support Vector Machine without the aid of external libraries
This repository contains a Juypter notebook in which Support Vector Machines (SVMs) are implemented based on various kernels and methods. 

On the one hand the Sequential Minimal Optimization (SMO) is utilized. This heuristic was presented in 1988 by John C. Platt in the paper ["A Fast Algorithm for Training Support Vector Machines"](https://www.microsoft.com/en-us/research/publication/sequential-minimal-optimization-a-fast-algorithm-for-training-support-vector-machines/). Furthermore, Stochastic Gradient Descent is also implemented. 

In addition, the behaviour of the hyperplanes of the two approaches is compared when training on various data sets.

The notebook is composed in German.